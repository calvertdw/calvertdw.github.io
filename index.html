<!DOCTYPE html>
<html lang="en">
<head>
    <title>Duncan Calvert, PhD Candidate</title>
    <link rel="stylesheet" href="main.css">
</head>
<body>
<h1>Duncan Calvert</h1>
<p>A chronological showcase of projects</p>
<h2>2024 - 2025: PhD Candidate & Research Associate at IHMC and UWF</h2>
<div>
    [Updates pending]
</div>
<h2>2019 - 2024: PhD Student & Research Associate at IHMC and UWF</h2>
<div>
    [Updates pending]
</div>
<div>
    <h3>A Coactive Door Traversal Behavior using Affordance Templates</h3>
    <p>Still under development, I am working on IHMC's next iteration of autonomous door traversal. I have integrated Bullet realtime physics and OpenCV based perception of ArUco markers in order to provide feedback for the behavior - even in simulation. The behavior is "coactive," that is, it is adhering to the design principles: observability, predictability, and directability.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/4v00bzmqV50" allowfullscreen></iframe>
</div>
<div>
    <h3>A Fast, Autonomous, Bipedal Walking Behavior over Rapid Planar Regions</h3>
    <p>By using a new rapid planar regions algorithm with GPU acceleration, and with the team at IHMC, I developed a walking behavior that actively perceives the terrain while it is walking. This is a step beyond prior implementations that required long static sensing times and were not robust to changes in terrain.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/qAtfV7hTzYg" allowfullscreen></iframe>
</div>
<div>
    <h3>Immersive and Low Latency VR Teleoperation of Humanoid Walking</h3>
    <p>Using the Valve Index VR headset, a Realsense L515, and an Ouster lidar, I developed a VR interface that allowed the user to place and execute footsteps over rough terrain for IHMC's DRC Atlas humanoid robot.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/D-mnw62r4vU" allowfullscreen></iframe>
</div>
<div>
    <h3>Explosive Ordnance Disposal Autonomy Demo</h3>
    <p>I led the team and developed a behavior architecture to reach for high levels of autonomy in a demo scenario for disposing of a mock pipe bomb, which required the robot accomplishing a sequence of difficult tasks: traversing rough terrain, pull door, debris clearance, push door, stairs, and manipulation of the bomb.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/jn5O_GcxCok" allowfullscreen></iframe>
</div>
<h2>2014 - 2019: Institute for Human and Machine Cognition, Research Associate</h2>
<div>
    <h3>Humanoid Behaviors</h3>
    <p>By combining the strengths of robots and humans, autonomous, fast, behaviors are under development. As the robot's autonomous capabilities increase, behaviors and their user interfaces can take over work from the human. In the video below, the operator selects a series of waypoints and the robot is left to accomplish the task, despite the rough terrain and control difficulty of bipedalism.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/Qv7a44lz3Z8" allowfullscreen></iframe>
</div>
<div>
    <h3>Teleoperation of Humanoid Robots in Virtual Reality</h3>
    <p>In the videos below, a humanoid robot is teleoperated with a VR system. The robot's arm movements track the human's in order to accomplish manipulation tasks.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/1dhJ4on1InM" allowfullscreen></iframe>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/SEo-aqHygf4" allowfullscreen></iframe>
</div>
<div>
    <h3>Java Composite Build Configuration</h3>
    <p>A complex build configuration using Gradle was developed to allow IHMC Robot Lab's 2 million lines of software to scale. The lab needed a way to hold open, proprietary, and standalone software projects in separate repositories while retaining the option to build from binary or source, interchangably, with ease. The configuration also allows for classpath isolation across build servers and IntelliJ and Eclipse IDEs.</p>
    <p>Project website: <a href="https://github.com/ihmcrobotics/ihmc-build" target="_blank">https://github.com/ihmcrobotics/ihmc-build</a></p>
</div>
<div>
    <h3>Continuous Integration Infrastructure</h3>
    <p>A continuous integration pipeline is designed and maintained for the IHMC Robot Lab to run around 5000 unit tests ranging from low level math and geometry libraries to full scale humanoid behavior simulations.</p>
    <img src="media/IHMC/CIPipeline.png" alt="CI Pipeline">
</div>
<div>
    <h3>Swing Over Planar Regions Trajectory Expander</h3>
    <p>A planning module was developed to avoid tripping on known obstacles while executing a footstep plan. The module iterates on a simulation of the collision model arcing through the footstep trajectory, detecting a collision and expanding the trajectory and trying again until there is no collision. The output is the two trajectory waypoints supported by the walking controller.</p>
    <img src="media/IHMC/SwingOverAlgorithm.png" alt="Algorithm Visualizer Screenshot">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/FBLr3BeOB2E" allowfullscreen></iframe>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/7qYEvJV5be8" allowfullscreen></iframe>
</div>
<div>
    <h3>DARPA Robotics Challenge</h3>
    <p>IHMC placed 2nd in the DARPA Robotics Challenge Finals in 2015. A 30 DoF hydraulic humanoid robot was piloted through an obstacle course from a warehouse a mile away with obstructed communication. The robot was able to accomplish all 8 tasks in under 1 hour on the second run. <a href="https://en.wikipedia.org/wiki/DARPA_Robotics_Challenge" target="_blank">(https://en.wikipedia.org/wiki/DARPA_Robotics_Challenge)</a></p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/TstdKAvPfEs" allowfullscreen></iframe>
</div>
<h2>2010 - 2014: Computer Science B.S., University of West Florida</h2>
<div>
    <h3>UWF Unmanned Ground Vehicle</h3>
    <p>This vehicle was designed and built by Duncan Calvert, Madison Fortenberry, and Kevin Van Landingham, beginning in August 2013 and ending in June 2014. The vehicle was designed according to strict specifications outlined by the 2014 International Ground Vehicle Competition official rules.<a href="http://www.igvc.org" target="_blank">(www.igvc.org)</a></p>
    <p>The main features of the vehicle hardware include 18" drive wheels, 4 cameras (2 side-facing wide angle), 5 ultrasonic sensors, 5 ARM-based system-on-chip embedded computers, 1 real-time ARM-based microcontroller, and power and safety equipment.
                    The cost of the project totaled roughly $3000, excluding the Hokuyo laser scanner, purchased previously for ~$4000.</p>
    <img src="media/UGV/UgvBestRendering.png" alt="UGV Final Configuration">
    <img src="media/UGV/UgvFinalConfig.png" alt="UGV Final Configuration">
    <p>The UWF Unmanned Ground Vehicle in its final configuration.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/W2OwEn3AQY0" allowfullscreen></iframe>
    <p>3D simulation in jMonkey Engine 3 using Java. Uses actual design models exported from Autodesk Inventor. Transmits a 270 degree sensor view via 780 data points at 10 Hz to a monitor utility.</p>
    <img src="media/UGV/UgvDesign1SuspensionLeg.png" alt="UGV CAD Design 1">
    <img src="media/UGV/UgvDesign2.png" alt="UGV CAD Design 2">
    <br>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/IAKZLkw2jdI" allowfullscreen></iframe>
    <br>
    <p>The two previous design iterations. We first tried to implement 4-wheel independent suspension, but this design turned out to be too costly in time and money. Secondly, we modeled and contructed a four wheel drive rigid body system, which, due to friction and the body geometry, was unable to pivot reliably. The vehicle was modeled in Autodesk Inventor.</p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ibIsyH7czlc" allowfullscreen></iframe>
</div>
<div>
    <h3>RILE Inc. (Robotics Interactive Learning Environment)</h3>
    <p>RILE is an educational robotics company that currently specializes in middle school level physics lessons.<a href="http://www.rileinc.com" target="_blank">www.rileinc.com</a></p>
    <p>The linear-motion-teaching robots use a PID algorithm to eliminate lateral motion as they assume their targeted velocity and acceleration vectors. They utilize ultrasonic rangefinders to record motion and avoid collisions.</p>
    <img src="media/RILE/RileGalileoFront.png" alt="RILE Galileo Prototype">
    <img src="media/RILE/RileGalileoComplete.png" alt="RILE Galileo Prototype">
    <img src="media/RILE/RileGalileo.png" alt="RILE Galileo Prototype">
    <img src="media/RILE/RileAssemblyGalileo.png" alt="RILE Galileo Prototype">
    <p>The images above show an early prototype of the latest version of RILE robots, internally codenamed "Galileo". This robot uses 3D printed parts for its structure.</p>
    <img src="media/RILE/RileRobotVex.png" alt="RILE Vex Robot">
    <img src="media/RILE/RileFleet.png" alt="RILE Vex Robot Fleet">
    <p>The images above show the first deployable prototype for RILE Inc., based on the VEX robotics platform. These robots run C++ code on an ARM9 processor runnning embedded linux. The robot uses the libquerk API developed at Carnegie Mellon University.</p>
</div>

<script>
"use strict";

class YouTubeEnhancer {
    constructor() {
        this.onYouTubeIframeAPIReadyCallbacks = [];
        this.apiLoaded = false;
        this.players = new Map();
    }

    // Main function to enhance all YouTube iframes on the page
    enhanceAllYouTubeVideos() {
        if (window.hideYTActivated) return;

        // Find all YouTube iframes
        const youtubeIframes = document.querySelectorAll('iframe[src*="youtube.com/embed"], iframe[src*="youtu.be"]');

        youtubeIframes.forEach(iframe => {
            this.enhanceYouTubeVideo(iframe);
        });

        this.loadYouTubeAPI();
        window.hideYTActivated = true;
    }

    // Enhance a single YouTube iframe
    enhanceYouTubeVideo(iframe) {
        // Create wrapper structure
        const outerWrap = document.createElement('div');
        outerWrap.className = 'hytPlayerWrapOuter';

        const playerWrap = document.createElement('div');
        playerWrap.className = 'hytPlayerWrap';

        // Insert wrapper before iframe
        iframe.parentNode.insertBefore(outerWrap, iframe);
        outerWrap.appendChild(playerWrap);
        playerWrap.appendChild(iframe);

        // Modify iframe src to include necessary parameters
        this.modifyIframeSrc(iframe);

        // Set up player events
        this.setupPlayerEvents(playerWrap, iframe);
    }

    modifyIframeSrc(iframe) {
        let src = iframe.src;

        // Add necessary YouTube parameters if not already present
        const params = {
            'fs': '0',
            'loop': '1', 
            'modestbranding': '1',
            'rel': '0',
            'enablejsapi': '1'
        };

        Object.keys(params).forEach(param => {
            if (!src.includes(param + '=')) {
                const separator = src.includes('?') ? '&' : '?';
                src += separator + param + '=' + params[param];
            }
        });

        iframe.src = src;
        iframe.setAttribute('frameborder', '0');
    }

    setupPlayerEvents(playerWrap, playerFrame) {
        const onPlayerStateChange = (event) => {
            if (event.data == YT.PlayerState.ENDED) {
                playerWrap.classList.add("ended");
            } else if (event.data == YT.PlayerState.PAUSED) {
                playerWrap.classList.add("paused");
            } else if (event.data == YT.PlayerState.PLAYING) {
                playerWrap.classList.remove("ended");
                playerWrap.classList.remove("paused");
            }
        };

        let player;
        this.onYouTubeIframeAPIReadyCallbacks.push(() => {
            player = new YT.Player(playerFrame, {
                events: {
                    'onStateChange': onPlayerStateChange
                }
            });
            this.players.set(playerWrap, player);
        });

        playerWrap.addEventListener("click", () => {
            if (player) {
                const playerState = player.getPlayerState();
                if (playerState == YT.PlayerState.ENDED) {
                    player.seekTo(0);
                } else if (playerState == YT.PlayerState.PAUSED) {
                    player.playVideo();
                }
            }
        });
    }

    loadYouTubeAPI() {
        if (!this.apiLoaded) {
            const tag = document.createElement('script');
            tag.src = "https://www.youtube.com/iframe_api";
            const firstScriptTag = document.getElementsByTagName('script')[0];
            firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
            this.apiLoaded = true;
        }
    }

    onAPIReady() {
        this.onYouTubeIframeAPIReadyCallbacks.forEach(callback => callback());
    }
}

// Create global instance
const youtubeEnhancer = new YouTubeEnhancer();

// Set up global YouTube API callback
window.onYouTubeIframeAPIReady = function() {
    youtubeEnhancer.onAPIReady();
};

// Auto-enhance all YouTube videos when DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
    youtubeEnhancer.enhanceAllYouTubeVideos();
});

// Utility function to enhance YouTube videos added dynamically
window.enhanceYouTubeVideos = function() {
    youtubeEnhancer.enhanceAllYouTubeVideos();
};
</script>
</body>
</html>
